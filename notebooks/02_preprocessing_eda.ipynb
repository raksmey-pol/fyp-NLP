{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bef9f15c",
   "metadata": {},
   "source": [
    "# Fake News Detection - Preprocessing & EDA\n",
    "\n",
    "This notebook performs comprehensive exploratory data analysis on the preprocessed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1798d630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from collections import Counter\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733fa491",
   "metadata": {},
   "source": [
    "## 1. Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e898880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "df = pd.read_csv('../data/processed/processed_news.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f9053b",
   "metadata": {},
   "source": [
    "## 2. Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7342a353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset info\n",
    "print(\"Dataset Information:\")\n",
    "print(\"=\"*50)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcf736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "df[['char_count', 'word_count', 'avg_word_length']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e44bfe",
   "metadata": {},
   "source": [
    "## 3. Class Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43edd540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "class_counts = df['label'].value_counts()\n",
    "class_percentages = df['label'].value_counts(normalize=True) * 100\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Count plot\n",
    "sns.countplot(data=df, x='label', ax=axes[0])\n",
    "axes[0].set_title('Class Distribution (Count)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Label (0=Fake, 1=Real)')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xticklabels(['Fake', 'Real'])\n",
    "\n",
    "# Percentage plot\n",
    "axes[1].pie(class_counts, labels=['Fake', 'Real'], autopct='%1.1f%%', startangle=90)\n",
    "axes[1].set_title('Class Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Fake news: {class_counts[0]:,} ({class_percentages[0]:.2f}%)\")\n",
    "print(f\"Real news: {class_counts[1]:,} ({class_percentages[1]:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8da1a54",
   "metadata": {},
   "source": [
    "## 4. Text Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92219029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text length comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Character count\n",
    "df[df['label']==0]['char_count'].hist(bins=50, alpha=0.6, label='Fake', ax=axes[0,0], color='red')\n",
    "df[df['label']==1]['char_count'].hist(bins=50, alpha=0.6, label='Real', ax=axes[0,0], color='green')\n",
    "axes[0,0].set_title('Character Count Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0,0].set_xlabel('Character Count')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "axes[0,0].legend()\n",
    "\n",
    "# Word count\n",
    "df[df['label']==0]['word_count'].hist(bins=50, alpha=0.6, label='Fake', ax=axes[0,1], color='red')\n",
    "df[df['label']==1]['word_count'].hist(bins=50, alpha=0.6, label='Real', ax=axes[0,1], color='green')\n",
    "axes[0,1].set_title('Word Count Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0,1].set_xlabel('Word Count')\n",
    "axes[0,1].set_ylabel('Frequency')\n",
    "axes[0,1].legend()\n",
    "\n",
    "# Average word length\n",
    "df[df['label']==0]['avg_word_length'].hist(bins=30, alpha=0.6, label='Fake', ax=axes[1,0], color='red')\n",
    "df[df['label']==1]['avg_word_length'].hist(bins=30, alpha=0.6, label='Real', ax=axes[1,0], color='green')\n",
    "axes[1,0].set_title('Average Word Length Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1,0].set_xlabel('Average Word Length')\n",
    "axes[1,0].set_ylabel('Frequency')\n",
    "axes[1,0].legend()\n",
    "\n",
    "# Box plot comparison\n",
    "df.boxplot(column='word_count', by='label', ax=axes[1,1])\n",
    "axes[1,1].set_title('Word Count by Label', fontsize=12, fontweight='bold')\n",
    "axes[1,1].set_xlabel('Label (0=Fake, 1=Real)')\n",
    "axes[1,1].set_ylabel('Word Count')\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bd6af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical comparison\n",
    "print(\"Text Statistics by Label:\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nFAKE NEWS:\")\n",
    "print(df[df['label']==0][['char_count', 'word_count', 'avg_word_length']].describe())\n",
    "print(\"\\nREAL NEWS:\")\n",
    "print(df[df['label']==1][['char_count', 'word_count', 'avg_word_length']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb03bba2",
   "metadata": {},
   "source": [
    "## 5. Word Cloud Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af7fc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word clouds for fake and real news\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Fake news word cloud\n",
    "fake_text = ' '.join(df[df['label']==0]['cleaned_text'].astype(str))\n",
    "wordcloud_fake = WordCloud(width=800, height=400, \n",
    "                           background_color='white',\n",
    "                           colormap='Reds',\n",
    "                           max_words=100).generate(fake_text)\n",
    "axes[0].imshow(wordcloud_fake, interpolation='bilinear')\n",
    "axes[0].set_title('Fake News - Most Common Words', fontsize=16, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Real news word cloud\n",
    "real_text = ' '.join(df[df['label']==1]['cleaned_text'].astype(str))\n",
    "wordcloud_real = WordCloud(width=800, height=400,\n",
    "                           background_color='white',\n",
    "                           colormap='Greens',\n",
    "                           max_words=100).generate(real_text)\n",
    "axes[1].imshow(wordcloud_real, interpolation='bilinear')\n",
    "axes[1].set_title('Real News - Most Common Words', fontsize=16, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36223f9d",
   "metadata": {},
   "source": [
    "## 6. Most Common Words Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af7c0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words(text_series, n=20):\n",
    "    \"\"\"Get top N most common words\"\"\"\n",
    "    all_words = ' '.join(text_series.astype(str)).split()\n",
    "    word_freq = Counter(all_words)\n",
    "    return word_freq.most_common(n)\n",
    "\n",
    "# Get top words for each class\n",
    "top_fake = get_top_words(df[df['label']==0]['cleaned_text'], n=20)\n",
    "top_real = get_top_words(df[df['label']==1]['cleaned_text'], n=20)\n",
    "\n",
    "# Create DataFrames\n",
    "df_fake_words = pd.DataFrame(top_fake, columns=['word', 'count'])\n",
    "df_real_words = pd.DataFrame(top_real, columns=['word', 'count'])\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "# Fake news top words\n",
    "axes[0].barh(df_fake_words['word'], df_fake_words['count'], color='red', alpha=0.7)\n",
    "axes[0].set_title('Top 20 Words in Fake News', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Frequency')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Real news top words\n",
    "axes[1].barh(df_real_words['word'], df_real_words['count'], color='green', alpha=0.7)\n",
    "axes[1].set_title('Top 20 Words in Real News', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Frequency')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff773fc7",
   "metadata": {},
   "source": [
    "## 7. Sample Texts Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9a77a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample fake news\n",
    "print(\"FAKE NEWS SAMPLE (Cleaned):\")\n",
    "print(\"=\"*80)\n",
    "sample_fake = df[df['label']==0].sample(1, random_state=42).iloc[0]\n",
    "print(f\"Original Title: {sample_fake.get('title', 'N/A')}\")\n",
    "print(f\"\\nCleaned Text (first 500 chars):\\n{sample_fake['cleaned_text'][:500]}...\")\n",
    "print(f\"\\nWord Count: {sample_fake['word_count']}\")\n",
    "print(f\"Character Count: {sample_fake['char_count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e37cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample real news\n",
    "print(\"REAL NEWS SAMPLE (Cleaned):\")\n",
    "print(\"=\"*80)\n",
    "sample_real = df[df['label']==1].sample(1, random_state=42).iloc[0]\n",
    "print(f\"Original Title: {sample_real.get('title', 'N/A')}\")\n",
    "print(f\"\\nCleaned Text (first 500 chars):\\n{sample_real['cleaned_text'][:500]}...\")\n",
    "print(f\"\\nWord Count: {sample_real['word_count']}\")\n",
    "print(f\"Character Count: {sample_real['char_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218e5962",
   "metadata": {},
   "source": [
    "## 8. Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b19d44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "corr_cols = ['label', 'char_count', 'word_count', 'avg_word_length']\n",
    "correlation = df[corr_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581c8e5e",
   "metadata": {},
   "source": [
    "## 9. Key Insights Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77871514",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"KEY INSIGHTS FROM EDA:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Class balance\n",
    "balance_ratio = (df['label']==0).sum() / (df['label']==1).sum()\n",
    "print(f\"\\n1. Class Balance: {balance_ratio:.2f}:1 (Fake:Real)\")\n",
    "if 0.8 <= balance_ratio <= 1.2:\n",
    "    print(\"   ✅ Dataset is well-balanced\")\n",
    "else:\n",
    "    print(\"   ⚠️ Dataset is imbalanced - may need SMOTE or class weights\")\n",
    "\n",
    "# Text length differences\n",
    "fake_avg_words = df[df['label']==0]['word_count'].mean()\n",
    "real_avg_words = df[df['label']==1]['word_count'].mean()\n",
    "print(f\"\\n2. Average Word Count:\")\n",
    "print(f\"   Fake news: {fake_avg_words:.0f} words\")\n",
    "print(f\"   Real news: {real_avg_words:.0f} words\")\n",
    "print(f\"   Difference: {abs(fake_avg_words - real_avg_words):.0f} words\")\n",
    "\n",
    "# Data quality\n",
    "print(f\"\\n3. Data Quality:\")\n",
    "print(f\"   Total samples: {len(df):,}\")\n",
    "print(f\"   Missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"   ✅ Ready for feature engineering\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375be8c7",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Phase 3: Feature Engineering**\n",
    "   - TF-IDF vectorization\n",
    "   - Word2Vec embeddings\n",
    "   - BERT embeddings\n",
    "\n",
    "2. **Phase 4: Model Development**\n",
    "   - Train traditional ML models\n",
    "   - Train deep learning models\n",
    "   \n",
    "3. **Phase 5: Model Evaluation**\n",
    "   - Compare model performance\n",
    "   - Select best model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
