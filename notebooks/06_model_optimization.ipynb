{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1efeed5f",
   "metadata": {},
   "source": [
    "# Phase 6: Model Optimization & Hyperparameter Tuning\n",
    "Fine-tune the best performing models and create ensemble methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36822acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0df186",
   "metadata": {},
   "source": [
    "## Option 1: Quick Optimization (Recommended)\n",
    "Run automated hyperparameter tuning for traditional ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13d9465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will take 10-20 minutes depending on your settings\n",
    "# Set tune_svm_flag = False to skip SVM tuning (saves ~20 minutes)\n",
    "%run ../src/optimization/hyperparameter_tuning.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689ab3a4",
   "metadata": {},
   "source": [
    "## Option 2: Manual Hyperparameter Tuning\n",
    "For more control over the optimization process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df315e21",
   "metadata": {},
   "source": [
    "### 2.1 Load Best Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746687e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation results to see which model performed best\n",
    "df_results = pd.read_csv('../results/model_comparison.csv')\n",
    "print(\"Top 3 Models:\")\n",
    "display(df_results.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea910c94",
   "metadata": {},
   "source": [
    "### 2.2 Load Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbda603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.optimization.hyperparameter_tuning import load_features\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_features('tfidf')\n",
    "\n",
    "print(f\"Train set: {X_train.shape}\")\n",
    "print(f\"Val set: {X_val.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1137d07d",
   "metadata": {},
   "source": [
    "### 2.3 Tune Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f588b42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.optimization.hyperparameter_tuning import tune_logistic_regression\n",
    "\n",
    "lr_model, lr_params = tune_logistic_regression(\n",
    "    X_train, y_train, X_val, y_val, \n",
    "    search_type='grid'  # or 'random'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2317a1d7",
   "metadata": {},
   "source": [
    "### 2.4 Tune Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2938e28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.optimization.hyperparameter_tuning import tune_random_forest\n",
    "\n",
    "rf_model, rf_params = tune_random_forest(\n",
    "    X_train, y_train, X_val, y_val,\n",
    "    search_type='random'  # Random search is faster for RF\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7899520c",
   "metadata": {},
   "source": [
    "### 2.5 Create Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6583cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.optimization.hyperparameter_tuning import create_ensemble_model\n",
    "\n",
    "# Combine best models\n",
    "models_dict = {\n",
    "    'logistic': lr_model,\n",
    "    'random_forest': rf_model\n",
    "}\n",
    "\n",
    "ensemble_model, voting_type = create_ensemble_model(\n",
    "    models_dict, X_train, y_train, X_val, y_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09f0517",
   "metadata": {},
   "source": [
    "### 2.6 Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d15b3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Evaluate ensemble\n",
    "y_pred = ensemble_model.predict(X_test)\n",
    "\n",
    "print(\"\\nENSEMBLE MODEL - TEST SET PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_pred, target_names=['Fake', 'Real']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "           xticklabels=['Fake', 'Real'],\n",
    "           yticklabels=['Fake', 'Real'])\n",
    "plt.title('Ensemble Model - Confusion Matrix', fontweight='bold')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c51abe4",
   "metadata": {},
   "source": [
    "## Option 3: Deep Learning Model Optimization\n",
    "Fine-tune LSTM, BiLSTM, or CNN-LSTM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e69ea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.optimization.hyperparameter_tuning import optimize_deep_learning_model\n",
    "\n",
    "# Choose model type: 'lstm', 'bilstm', or 'cnn_lstm'\n",
    "model_type = 'lstm'  # Change this\n",
    "\n",
    "# This will take 30-60 minutes depending on GPU\n",
    "best_model, best_params, tuning_results = optimize_deep_learning_model(\n",
    "    model_type=model_type,\n",
    "    epochs_range=[10, 15, 20],\n",
    "    batch_sizes=[64, 128],\n",
    "    learning_rates=[0.001, 0.0005]\n",
    ")\n",
    "\n",
    "print(\"\\nTuning Results:\")\n",
    "display(tuning_results.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8326bc",
   "metadata": {},
   "source": [
    "### Visualize Hyperparameter Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1360a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning rate vs F1 score\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "tuning_results.groupby('learning_rate')['val_f1'].mean().plot(kind='bar')\n",
    "plt.title('Learning Rate Impact')\n",
    "plt.ylabel('Validation F1')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "tuning_results.groupby('batch_size')['val_f1'].mean().plot(kind='bar')\n",
    "plt.title('Batch Size Impact')\n",
    "plt.ylabel('Validation F1')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "tuning_results.groupby('epochs')['val_f1'].mean().plot(kind='bar')\n",
    "plt.title('Epochs Impact')\n",
    "plt.ylabel('Validation F1')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56bc71d",
   "metadata": {},
   "source": [
    "## Comparison: Before vs After Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d8bddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original results\n",
    "original_results = pd.read_csv('../results/model_comparison.csv')\n",
    "\n",
    "# You can manually add optimized results here\n",
    "print(\"BEFORE OPTIMIZATION:\")\n",
    "display(original_results.head())\n",
    "\n",
    "# After running optimization, compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842b5182",
   "metadata": {},
   "source": [
    "## Save Optimized Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd6b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Save ensemble model\n",
    "if 'ensemble_model' in locals():\n",
    "    with open('../models/ensemble_optimized.pkl', 'wb') as f:\n",
    "        pickle.dump(ensemble_model, f)\n",
    "    print(\"âœ… Ensemble model saved!\")\n",
    "\n",
    "# Save individual optimized models\n",
    "if 'lr_model' in locals():\n",
    "    with open('../models/logistic_optimized.pkl', 'wb') as f:\n",
    "        pickle.dump(lr_model, f)\n",
    "    print(\"âœ… Optimized Logistic Regression saved!\")\n",
    "\n",
    "if 'rf_model' in locals():\n",
    "    with open('../models/random_forest_optimized.pkl', 'wb') as f:\n",
    "        pickle.dump(rf_model, f)\n",
    "    print(\"âœ… Optimized Random Forest saved!\")\n",
    "\n",
    "# Save best params\n",
    "os.makedirs('../results/optimization', exist_ok=True)\n",
    "if 'lr_params' in locals():\n",
    "    with open('../results/optimization/lr_best_params.pkl', 'wb') as f:\n",
    "        pickle.dump(lr_params, f)\n",
    "\n",
    "if 'rf_params' in locals():\n",
    "    with open('../results/optimization/rf_best_params.pkl', 'wb') as f:\n",
    "        pickle.dump(rf_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0512acd9",
   "metadata": {},
   "source": [
    "## Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d3937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "                    PHASE 6: OPTIMIZATION COMPLETE!\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "âœ… Completed Tasks:\n",
    "   â€¢ Hyperparameter tuning for traditional ML models\n",
    "   â€¢ Created ensemble models with voting classifiers\n",
    "   â€¢ Optimized best performing models\n",
    "   â€¢ Saved optimized models for deployment\n",
    "\n",
    "ğŸ“Š Results Saved:\n",
    "   â€¢ Optimized models: models/\n",
    "   â€¢ Best parameters: results/optimization/\n",
    "   â€¢ Tuning results: results/*_tuning_results.csv\n",
    "\n",
    "ğŸš€ NEXT STEP: Phase 7 - Deployment\n",
    "   â€¢ Create Flask/FastAPI web application\n",
    "   â€¢ Build interactive UI for predictions\n",
    "   â€¢ Containerize with Docker\n",
    "   â€¢ Deploy to cloud (Heroku/AWS/GCP)\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
